{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Sentiment Analyzer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "pycharm-38557d32",
   "language": "python",
   "display_name": "PyCharm (Twitter-Sentiment-project)"
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "upXaoMXgM4rG",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "outputId": "db0592dd-a6e4-4171-8ad2-582393235f89"
   },
   "source": [
    "# Load data\n",
    "import pandas as pd\n",
    "\n",
    "col_names = ['sentiment','id','date','query_string','user','text']\n",
    "data_path = '/content/drive/My Drive/Colab Notebooks/training.1600000.processed.noemoticon.csv'\n",
    "\n",
    "tweet_data = pd.read_csv(data_path, header=None, names=col_names, encoding=\"ISO-8859-1\").sample(frac=1) # .sample(frac=1) shuffles the data\n",
    "tweet_data = tweet_data[['sentiment', 'text']] # Disregard other columns\n",
    "print(tweet_data.head())"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "         sentiment                                               text\n",
      "1049857          4                                           with kv \n",
      "583013           0    Hey ya'll! Wats up? Haven't been on im a while \n",
      "512083           0    Yesterday... I was tired. Today... I am bored. \n",
      "1098537          4                                        sunbathin' \n",
      "554878           0  @MTVindia Can you provide some of them here......\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5PLmioxmOf09",
    "colab_type": "code",
    "colab": {}
   },
   "source": [],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ASIVy6dkM9z5",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Preprocess function\n",
    "import re\n",
    "allowed_chars = ' AaBbCcDdEeFfGgHhIiJjKkLlMmNnOoPpQqRrSsTtUuVvWwXxYyZz0123456789~`!@#$%^&*()-=_+[]{}|;:\",./<>?'\n",
    "punct = '!?,.@#'\n",
    "maxlen = 280\n",
    "\n",
    "def preprocess(text):\n",
    "    return ''.join([' ' + char + ' ' if char in punct else char for char in [char for char in re.sub(r'http\\S+', 'http', text, flags=re.MULTILINE) if char in allowed_chars]])[:maxlen]"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YbbnQpHjPZl-",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Apply preprocessing\n",
    "tweet_data['text'] = tweet_data['text'].apply(preprocess)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xTx4caLMPfsD",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "9e88ee09-dda3-4712-ddbc-5ab1d2e6c6e2"
   },
   "source": [
    "# Put __label__ in front of each sentiment\n",
    "tweet_data['sentiment'] = '__label__' + tweet_data['sentiment'].astype(str)"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "NumExpr defaulting to 2 threads.\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZImmIZ8UPqah",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Save data\n",
    "import os\n",
    "\n",
    "# Create directory for saving data if it does not already exist\n",
    "data_dir = './processed-data'\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "\n",
    "# Save a percentage of the data (you could also only load a fraction of the data instead)\n",
    "amount = 0.125\n",
    "\n",
    "tweet_data.iloc[0:int(len(tweet_data)*0.8*amount)].to_csv(data_dir + '/train.csv', sep='\\t', index=False, header=False)\n",
    "tweet_data.iloc[int(len(tweet_data)*0.8*amount):int(len(tweet_data)*0.9*amount)].to_csv(data_dir + '/test.csv', sep='\\t', index=False, header=False)\n",
    "tweet_data.iloc[int(len(tweet_data)*0.9*amount):int(len(tweet_data)*1.0*amount)].to_csv(data_dir + '/dev.csv', sep='\\t', index=False, header=False)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-gEpcI2jPzGl",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "8eb233fc-83ec-4192-d7e2-f8b6d4afb7d3"
   },
   "source": [
    "# Memory management\n",
    "del tweet_data\n",
    "import gc; gc.collect()"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 11
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "URkw9eHyP5MW",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "outputId": "ddce4685-9fd2-42a0-c074-6c58d894eda3"
   },
   "source": [
    "# Load the data into Corpus format\n",
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from pathlib import Path\n",
    "\n",
    "corpus = NLPTaskDataFetcher.load_classification_corpus(Path(data_dir), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "'pattern' package not found; tag filters are not available for English\n",
      "PyTorch version 1.4.0 available.\n",
      "TensorFlow version 2.2.0-rc2 available.\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "2020-04-05 16:50:24,827 Reading data from processed-data\n",
      "2020-04-05 16:50:24,827 Train: processed-data/train.csv\n",
      "2020-04-05 16:50:24,831 Dev: processed-data/dev.csv\n",
      "2020-04-05 16:50:24,832 Test: processed-data/test.csv\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:452: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  train_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:457: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  test_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n",
      "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:464: DeprecationWarning: Call to deprecated function (or staticmethod) read_text_classification_file. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
      "  dev_file, tokenizer=tokenizer, max_tokens_per_doc=max_tokens_per_doc\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PM5YvCsUQcAj",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "outputId": "d9e4b256-2c99-464d-c7a5-45fb47772109"
   },
   "source": [
    "label_dict = corpus.make_label_dictionary()"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "2020-04-05 16:52:16,668 Computing label dictionary. Progress:\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 160000/160000 [00:00<00:00, 326305.79it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "2020-04-05 16:52:17,195 [b'4', b'0']\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "icen9Jc6Q6Nu",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "outputId": "c0dff012-9478-49ea-f79f-ebf1c5ef52c7"
   },
   "source": [
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings\n",
    "\n",
    "word_embeddings = [WordEmbeddings('glove'),\n",
    "#                    FlairEmbeddings('news-forward'),\n",
    "#                    FlairEmbeddings('news-backward')\n",
    "                  ]"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "2020-04-05 16:54:41,759 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmpgg2487zc\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 160000128/160000128 [00:09<00:00, 17258887.88B/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "2020-04-05 16:54:51,712 copying /tmp/tmpgg2487zc to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "2020-04-05 16:54:52,309 removing temp file /tmp/tmpgg2487zc\n",
      "2020-04-05 16:54:54,124 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim not found in cache, downloading to /tmp/tmp0gh_ufhz\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 21494764/21494764 [00:02<00:00, 10072804.01B/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "2020-04-05 16:54:56,913 copying /tmp/tmp0gh_ufhz to cache at /root/.flair/embeddings/glove.gensim\n",
      "2020-04-05 16:54:56,935 removing temp file /tmp/tmp0gh_ufhz\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\n",
      "loading Word2VecKeyedVectors object from /root/.flair/embeddings/glove.gensim\n",
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "loading vectors from /root/.flair/embeddings/glove.gensim.vectors.npy with mmap=None\n",
      "setting ignored attribute vectors_norm to None\n",
      "loaded /root/.flair/embeddings/glove.gensim\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yGXa0e9BRACI",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Initialize embeddings\n",
    "from flair.embeddings import DocumentRNNEmbeddings\n",
    "\n",
    "document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5QumQaGtRKnP",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Create model\n",
    "from flair.models import TextClassifier\n",
    "\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MOqIz3ZjRTuN",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Create model trainer\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer = ModelTrainer(classifier, corpus)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9iZ3-Jh9RWCM",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 806
    },
    "outputId": "dd98f251-13dc-4e58-be95-cd3b485be8c2"
   },
   "source": [
    "# Train the model\n",
    "trainer.train('model-saves',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              anneal_factor=0.5,\n",
    "              patience=8,\n",
    "              max_epochs=5)"
   ],
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "2020-04-05 17:11:25,926 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-05 17:11:25,931 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=100, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512, batch_first=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2020-04-05 17:11:25,934 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-05 17:11:25,936 Corpus: \"Corpus: 160000 train + 20000 dev + 20000 test sentences\"\n",
      "2020-04-05 17:11:25,937 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-05 17:11:25,940 Parameters:\n",
      "2020-04-05 17:11:25,942  - learning_rate: \"0.1\"\n",
      "2020-04-05 17:11:25,944  - mini_batch_size: \"32\"\n",
      "2020-04-05 17:11:25,945  - patience: \"8\"\n",
      "2020-04-05 17:11:25,945  - anneal_factor: \"0.5\"\n",
      "2020-04-05 17:11:25,946  - max_epochs: \"5\"\n",
      "2020-04-05 17:11:25,948  - shuffle: \"True\"\n",
      "2020-04-05 17:11:25,948  - train_with_dev: \"False\"\n",
      "2020-04-05 17:11:25,950  - batch_growth_annealing: \"False\"\n",
      "2020-04-05 17:11:25,951 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-05 17:11:25,951 Model training base path: \"model-saves\"\n",
      "2020-04-05 17:11:25,953 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-05 17:11:25,954 Device: cuda:0\n",
      "2020-04-05 17:11:25,955 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-05 17:11:25,956 Embeddings storage mode: cpu\n",
      "2020-04-05 17:11:28,827 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-05 17:11:28,829 Testing using best model ...\n",
      "2020-04-05 17:11:35,945 0.5799\t0.5799\t0.5799\n",
      "2020-04-05 17:11:35,947 \n",
      "MICRO_AVG: acc 0.4084 - f1-score 0.5799\n",
      "MACRO_AVG: acc 0.3955 - f1-score 0.5611\n",
      "0          tp: 3731 - fp: 2072 - fn: 6330 - tn: 7867 - precision: 0.6429 - recall: 0.3708 - accuracy: 0.3075 - f1-score: 0.4703\n",
      "4          tp: 7867 - fp: 6330 - fn: 2072 - tn: 3731 - precision: 0.5541 - recall: 0.7915 - accuracy: 0.4836 - f1-score: 0.6519\n",
      "2020-04-05 17:11:35,948 ----------------------------------------------------------------------------------------------------\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'dev_loss_history': [],\n",
       " 'dev_score_history': [],\n",
       " 'test_score': 0.5799,\n",
       " 'train_loss_history': []}"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 32
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bl7Sb3I5RZ8w",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "outputId": "1a471144-62e3-4746-bc48-bc36c2e0fb91"
   },
   "source": [
    "# Load the model and make predictions\n",
    "from flair.data import Sentence\n",
    "\n",
    "classifier = TextClassifier.load('model-saves/final-model.pt')\n",
    "\n",
    "pos_sentence = Sentence(preprocess('I love Python!'))\n",
    "neg_sentence = Sentence(preprocess('Python is the worst!'))\n",
    "\n",
    "classifier.predict(pos_sentence)\n",
    "classifier.predict(neg_sentence)\n",
    "\n",
    "print(pos_sentence.labels, neg_sentence.labels)"
   ],
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "2020-04-05 17:11:55,622 loading file model-saves/final-model.pt\n",
      "[4 (0.7186697721481323)] [4 (0.5976102352142334)]\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}